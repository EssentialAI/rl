
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>What is Reinforcement Learning? &#8212; Reinforcement Learning Notes</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/brain1.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="&lt;no title&gt;" href="SuperMarioBros-v0.html" />
    <link rel="prev" title="Contents of this book" href="table_of_contents.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/test_final.gif" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Reinforcement Learning Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Preface
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="table_of_contents.html">
   Contents of this book
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   What is Reinforcement Learning?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Prob_warmup.html">
   Probability Warmup
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lz_prog/notations.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   What is Reinforcement Learning?
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-reinforcement-learning">
   Why Reinforcement Learning?
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning">
   Machine Learning
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#is-rl-same-as-ml">
   Is RL same as ML?
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rl-fundamentals">
   RL Fundamentals
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <!-- #region -->
<p><span style="color:blue;"><em>You can navigate through this page quickly by using the navigation list on the right-hand side of this page.</em></span></p>
<div class="section" id="what-is-reinforcement-learning">
<h1>What is Reinforcement Learning?<a class="headerlink" href="#what-is-reinforcement-learning" title="Permalink to this headline">¶</a></h1>
<p>As mentioned in the Preface, <span style="color:blue;">“Reinforcement Learning is a field that deals with building models that mimic human behaviour to learn.”</span> To completely understand how Reinforcement Learning (RL) models work, let’s try and understand how humans learn.</p>
<p>Humans learn in a “cause and effect” fashion. For example, we humans do not know how to code right from birth. Learning to code is an interactive process. We make errors in the code, debug them, progressively gain experience about the consequences of actions and what actions to perform to achieve maximum success. <em>Learning from the interaction is a foundational idea underlying nearly all theories of learning and intelligence.</em></p>
<div class="tip admonition">
<p class="admonition-title">What is RL?</p>
<p>Reinforcement Learning is a field that aims to build models that try to achieve ‘goal-directed learning from interaction’ than other approaches to machine learning. <span style="color:blue;">Reinforcement learning (RL) tells you how to make the best decisions, sequentially, within a context, to maximize a real-life measure of success.</span></p>
<p><strong>Learning by ‘reinforcement’ combines two tasks. The first is exploring new situations. The second is using that experience to make better decisions.</strong></p>
<p><em>We shall discuss the concepts of exploration, exploitation, and optimal decisions in the # chapter.</em></p>
</div>
<div class="idea admonition">
<p class="admonition-title">Note</p>
<p>The characteristics of ‘Trial-and-Error based search’ and ‘Delayed Reward’ are the two most important distinguishing features of Reinforcement Learning.</p>
</div>
<p><em>Differences between Machine Learning and Reinforcement Learning are discussed in detail below.</em></p>
</div>
<div class="section" id="why-reinforcement-learning">
<h1>Why Reinforcement Learning?<a class="headerlink" href="#why-reinforcement-learning" title="Permalink to this headline">¶</a></h1>
<p>One key feature of reinforcement learning is that it explicitly considers the <em>whole</em> problem of a goal-directed agent interacting with an uncertain environment. This is in contrast to many approaches that consider subproblems without addressing how they might fit into a larger picture.</p>
<p>Reinforcement learning is part of a decades-long trend within artificial intelligence and machine learning toward greater integration with statistics, optimization, and other mathematical subjects.</p>
<p>For example, the ability of some reinforcement learning methods to learn with parameterized approximators addresses the classical “curse of dimensionality” in operations research and control theory. More distinctively, reinforcement learning has also interacted strongly with psychology and neuroscience, with substantial benefits going both ways. Of all the forms of machine learning, reinforcement learning is the closest to the kind of learning that humans and other animals do, and many of the core algorithms of reinforcement learning were originally inspired by biological learning systems.</p>
<p>A good way to understand reinforcement learning is to consider some of the examples and possible applications that have guided its development.</p>
<ul class="simple">
<li><p>A master chess player makes a move. The choice is informed both by planning—anticipating possible replies and counter replies—and by immediate, intuitive judgments of the desirability of particular positions and moves.<br></p></li>
<li><p>An adaptive controller adjusts parameters of a petroleum refinery’s operation in real time. The controller optimizes the yield/cost/quality trade-of on the basis of specified marginal costs without sticking strictly to the set points originally suggested by engineers.<br></p></li>
<li><p>A gazelle calf struggles to its feet minutes after being born. Half an hour later it is running at 20 miles per hour.<br></p></li>
<li><p>A mobile robot decides whether it should enter a new room in search of more trash to collect or start trying to find its way back to its battery recharging station. It makes its decision based on the current charge level of its battery and how quickly and easily it has been able to find the recharger in the past.<br></p></li>
</ul>
</div>
<div class="section" id="machine-learning">
<h1>Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline">¶</a></h1>
<div class="idea admonition">
<p class="admonition-title">Note</p>
<p><a class="reference external" href="https://rl-book.com/">Source</a> I consider ML a child of data science, which is an overarching scientific field that investigates the data generated by phenomena. I dislike the term artificial intelligence (AI) for a similar reason; it is hard enough to
define what intelligence is, let alone specify how it is achieved.</p>
</div>
<p><span style="color:blue;">Supervised Machine Learning.</span>
In this type of Machine Learning, models learn to generalize from numerous training images provided with labels. In Supervised Machine Learning, the data is split into training and test datasets. Each example is a description of a situation together with a specification, the label, of the correct action the system should take to that situation, which is often to identify a category to which the situation belongs.</p>
<p>The objective of this kind of learning is for the system to extrapolate or generalize its responses so that it acts correctly in situations not present in the training set.</p>
<p><span style="color:blue;">Unsupervised Machine Learning.</span>
In this type of Machine Learning, models try to figure out patterns in the data without labels. Unsupervised learning is aimed at finding structures hidden in collections of unlabelled data.</p>
</div>
<div class="section" id="is-rl-same-as-ml">
<h1>Is RL same as ML?<a class="headerlink" href="#is-rl-same-as-ml" title="Permalink to this headline">¶</a></h1>
<p>Although one might be tempted to think of reinforcement learning as a kind of unsupervised learning (because it does not rely on examples of correct behavior), reinforcement learning tries to maximize a reward signal instead of trying to find a hidden structure.</p>
<p>Reinforcement learning takes a different track compared to Machine Learning, starting with a complete, interactive, goal-seeking agent. All reinforcement learning agents have explicit goals, can sense aspects of their environments, and can choose actions to influence their environments.</p>
<p>When reinforcement learning involves planning, it has to address the interplay between planning and real-time action selection, as well as the question of how environment models are acquired and improved.</p>
</div>
<div class="section" id="rl-fundamentals">
<h1>RL Fundamentals<a class="headerlink" href="#rl-fundamentals" title="Permalink to this headline">¶</a></h1>
<p><span style="color:blue;">Agent:</span>
An agent is a software program that learns to make intelligent decisions. For instance, a chess player can be considered an agent since the player learns to make the best moves (decisions) to win the game. Similarly, Mario in a Super Mario Bros video game can be considered an agent since Mario explores the game and learns to make the best moves in the game.</p>
<p><span style="color:blue;">Environment:</span>
The environment is the world of the agent. The agent interacts within the environments. For example, a chessboard is called the environment for the chess player agent.</p>
<p><span style="color:blue;">State and Action:</span>
A state is a position or a moment in the environment that the agent can be in. There can be many <code class="docutils literal notranslate"><span class="pre">positions</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">chess</span> <span class="pre">board</span> <span class="pre">environment</span></code> that we discussed earlier. All these positions on the chess board are cosidered to be the state. The movement of the chess player agent (forward, backwward, right, and left) are known as actions. (A state is denoted by <span class="math notranslate nohighlight">\(s\)</span>, and an action is denoted by <span class="math notranslate nohighlight">\(a\)</span>).</p>
<p><span style="color:blue;">Reward:</span>
As we discussed earlier, the agent interacts with the environments by performing actions. Every action has a reward associated to it. This reward is a numerical value, <em>(+1 or -1 for example)</em> that denotes if the agent performed an optimal action or not.</p>
<p>The goal of the RL agent is to <code class="docutils literal notranslate"><span class="pre">maximize</span> <span class="pre">this</span> <span class="pre">reward</span></code> by performing an optimal set of actions.</p>
<p><span style="color:blue;">Policy:</span>
A policy defines the learning agent’s way of behaving at a given time.</p>
<p><span style="color:blue;">Value Functions:</span>
Whereas the reward signal indicates what is good in an immediate sense, a value function specifies what is good in the long run. Roughly speaking, the value of a state is the total amount of reward an agent can expect to accumulate over the future, starting from that state. Rewards are in a sense primary, whereas values, as predictions of rewards, are secondary. Without rewards there could be no values, and the only purpose of estimating values is to achieve more reward. Rewards are basically given directly by the environment, but values must be estimated and re-estimated from the sequences of observations an agent makes over its entire lifetime.</p>
<p><span style="color:blue;">Model-based and Model-free methods:</span>
Methods for solving reinforcement learning problems that use models and planning are called model-based methods, as opposed to simpler model-free methods that are explicitly trial-and-error learners—viewed as almost the opposite of planning.</p>
<!-- #endregion -->
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lz_prog"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="table_of_contents.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Contents of this book</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="SuperMarioBros-v0.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">&lt;no title&gt;</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Naresh Kumar<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>